{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import pickle\n",
    "import math\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from lib.quantflow.model.models.seq2seq_attn import seq2seq_attention, one_step_attention\n",
    "from lib.quantflow.model.models.resnet.resnet501D import ResNet50\n",
    "from lib.quantflow.model.models.lstm_model import generate_lstm\n",
    "from lib.quantflow.generators import WindowGenerator\n",
    "from lib.quantflow.model.callback import LossHistory\n",
    "from lib.quantflow.model.loss import focal_loss\n",
    "from lib.quantflow.utils import AutoSaver\n",
    "from lib.quantflow.trade import TradeMode\n",
    "\n",
    "\n",
    "def train_config(path, model, stride, window, forward, BN, mode, window_norm, algo, dropout, hidden_size, batch_size):\n",
    "    mod_path = path\n",
    "    if not os.path.exists(mod_path):\n",
    "        os.makedirs(mod_path)\n",
    "    with open(mod_path+'model_info.txt', 'a') as f:\n",
    "        f.write(\"DataInfo==================================================\\n\")\n",
    "        f.write(\"stride: %s\\nwindow_width: %s\\nlabel_width: %s\\nshift: %s\\nloss: %s\\nmode: %s\\nModel: %s\\n WindowNorm: %s\\n\" % (str(stride), str(window), str(forward), str(window_norm), str(model.loss[0]),str(mode),str(algo),str(window_norm)))\n",
    "        f.write(\"Model Info==================================================\\n\")\n",
    "        f.write(\"BatchNorm: %s\\nDropout: %s\\nHiddenSize: %s\\n\" % (str(BN), str(dropout), str(hidden_size)))\n",
    "        f.write(\"Model==================================================\\n\")\n",
    "        try:\n",
    "            model.summary(print_fn= f.write)\n",
    "        except:\n",
    "            print(\"Cannot print model architectures!!\")\n",
    "    csv_log = CSVLogger(mod_path+'trn_log.csv')\n",
    "    log_dir = mod_path+\"log/\"\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
    "    if not os.path.exists(mod_path+\"mod/\"):\n",
    "        os.makedirs(mod_path+\"mod/\")\n",
    "    checkpointer = AutoSaver(filepath=mod_path+\"mod/\"+\"weights-{epoch:02d}-{val_loss:.2f}.hdf5\", load_weights_on_restart=True,\n",
    "                            monitor='val_loss', mode='auto', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "    return mod_path, csv_log, tensorboard_callback, checkpointer\n",
    "\n",
    "\n",
    "########################################################\n",
    "plot_path = \"./results/statics/\"\n",
    "label_column = ['close']\n",
    "save_path = \"./results/\"\n",
    "window_norm = False\n",
    "dropout_rate = 0.2\n",
    "mode = 'regression'\n",
    "hidden_size = 200\n",
    "input_width = 24\n",
    "label_width = 24\n",
    "batch_size = 32\n",
    "stride = 1\n",
    "shift = 1\n",
    "BN = True\n",
    "########################################################\n",
    "\n",
    "\n",
    "# Load Dats\n",
    "with open(\"../data/data.pk\", 'rb') as f:\n",
    "    raw = pickle.load(f)\n",
    "\n",
    "# Split training and testing set\n",
    "test = raw['2019-11-30 23:00:00':'2020-02-27 16:00:00']\n",
    "data = raw['2019-01-01 00:00:00':'2019-11-30 23:00:00']\n",
    "\n",
    "\n",
    "# 按列归一化数据 normalization\n",
    "train_mean = data.mean()\n",
    "train_std = data.std()\n",
    "data = (data - train_mean) / train_std\n",
    "test = (test - train_mean) / train_std\n",
    "\n",
    "# 提琴图 violin plot\n",
    "# raw_std = (raw - train_mean) / train_std\n",
    "# raw_std = raw_std.melt(var_name='Column', value_name='Normalized')\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# ax = sns.violinplot(x='Column', y='Normalized', data=raw_std)\n",
    "# _ = ax.set_xticklabels(raw.keys(), rotation=90)\n",
    "\n",
    "# Trade mode\n",
    "tMode = TradeMode(rf=0.002, commission=0.005, mode=mode)\n",
    "\n",
    "# Windows generator\n",
    "wininst = WindowGenerator(input_width=input_width, label_width=label_width, shift=shift, label_columns=label_column, train_df=data, val_df=test,\n",
    "                      plot_path=plot_path, stride=stride)\n",
    "print(wininst)\n",
    "\n",
    "# Generate datasets\n",
    "trainset = wininst.train\n",
    "valset = wininst.val\n",
    "\n",
    "# DEBUG WIN GEN FUN\n",
    "# example_window = tf.stack([np.array(data[:wininst.total_window_size]),\n",
    "#                            np.array(data[100:100+wininst.total_window_size]),\n",
    "#                            np.array(data[200:200+wininst.total_window_size])])\n",
    "#\n",
    "# example_inputs, example_labels = wininst.split_window(example_window)\n",
    "# print('All shapes are: (batch, time, features)')\n",
    "# print(f'Window shape: {example_window.shape}')\n",
    "# print(f'Inputs shape: {example_inputs.shape}')\n",
    "# print(f'labels shape: {example_labels.shape}')\n",
    "\n",
    "# ResLSTM\n",
    "model_name = \"ResLSTM_single_out\"\n",
    "class ResidualWrapper(tf.keras.Model):\n",
    "  def __init__(self, model):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "\n",
    "  def call(self, inputs, *args, **kwargs):\n",
    "    delta = self.model(inputs, *args, **kwargs)\n",
    "    selected_inputs = tf.stack(\n",
    "        [inputs[:, :, wininst.column_indices[name]] for name in wininst.label_columns],\n",
    "        axis=-1)\n",
    "    # The prediction for each timestep is the input\n",
    "    # from the previous time step plus the delta\n",
    "    # calculated by the model.\n",
    "    return selected_inputs + delta\n",
    "\n",
    "model = ResidualWrapper(\n",
    " tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input((input_width, len(data.columns))),\n",
    "    # Shape [batch, time, features] => [batch, time, lstm_units]\n",
    "    # tf.compat.v1.keras.layers.CuDNNLSTM(24, return_sequences=True),\n",
    "    # tf.keras.layers.Activation('relu'),\n",
    "    # tf.keras.layers.Dropout(dropout_rate),\n",
    "    tf.compat.v1.keras.layers.CuDNNLSTM(24, return_sequences=True),\n",
    "    tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dropout(dropout_rate),\n",
    "\n",
    "    # tf.keras.layers.Dense(units=32),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.Activation('relu'),\n",
    "    tf.keras.layers.Dense(units=32),\n",
    "    # tf.keras.layers.BatchNormalization(),\n",
    "    # tf.keras.layers.Activation('relu'),\n",
    "\n",
    "    # Shape => [batch, time, features]\n",
    "    tf.keras.layers.Dense(units=1, activation='linear', kernel_initializer=tf.initializers.zeros)\n",
    "]))\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
    "mod_path = save_path + datetime.datetime.now().strftime(\"%Y_%m_%d-%H_%M_%S\")+\"/\"\n",
    "history = LossHistory(labels=[0, 1, 2], trade_mode=wininst, plot_fn=wininst.plot, save_path=mod_path+'images/')\n",
    "mod_path, csv_log, tensorboard_callback, checkpointer = train_config(mod_path, model, stride, input_width, label_width, BN, mode, window_norm,\n",
    "                                                              model_name, dropout_rate, hidden_size, batch_size, shift)\n",
    "\n",
    "# Train model\n",
    "model.fit(trainset, epochs=500, validation_data=valset, batch_size=batch_size,\n",
    "          callbacks=[tensorboard_callback, csv_log, history, checkpointer], shuffle=True)# history, class_weight=class_weights, sample_weight=sample_weights,\n",
    "\n",
    "for i in range(10):\n",
    "    wininst.plot(model=model, plot_mode='iter', plot_name='./results/statics/' + str(i) + '.png')\n",
    "\n",
    "# Each element is an (inputs, label) pair\n",
    "# w1.train.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval\n",
    "if not os.path.exists(mod_path + 'eval'):\n",
    "    os.makedirs(mod_path + 'eval')\n",
    "wininst.plot(model=model)\n",
    "\n",
    "results = model.evaluate(wininst.val)\n",
    "with open(mod_path + 'eval/eval_metrics.txt', 'w') as f:\n",
    "    f.write(\" loss:                  - mae: \\n\")\n",
    "    f.write(str(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
